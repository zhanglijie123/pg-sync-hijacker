# pg数据库翻译文档

#### 系统架构

##### 技术架构图

<div drawio-diagram="47"><img src="http://note.yelou.wang/uploads/images/drawio/2022-08/drawing-1-1659804558.png" alt=""/></div>

##### 实时翻译流程图

<div drawio-diagram="52"><img src="http://note.yelou.wang/uploads/images/drawio/2022-08/drawing-1-1659808102.png" alt=""/></div>

#### 相关技术实现

##### 1. 如何实时采集pg数据库变动数据？

基于CDC（Changing Data Capture）思想， 并且利用pg提供的逻辑解码，复制协议，复制槽功能实现。

按照 PostgreSQL 的复制协议编写一个"逻辑从库" ，从数据库中实时地，流式地接受逻辑解码后的变更事件，完成自己定义的处理逻辑，并及时向数据库汇报自己的消息消费进度。

##### 2. 如何保证数据顺序性？

根据tablename确定kafka的topic和partition，利用kafka同一个partition的顺序性来保证数据的顺序性

##### 3. 如何提高数据处理能力？

- 区分topic，根据数据量，表数量等指标区分不同的topic。利用多个topic来提高服务消费能力以及减轻kafka压力。 
    - 程序支持表名与topic对应关系的配置。
    - 程序根据配置信息划分节点与topic的对应关系，进行消费。
- 以批处理结合线程池的方式处理数据，提高单表数据处理速度。 
    - 为了保证数据顺序性，单表的数据只会有一个consumer消费。
    - 该consumer采用异步处理的方式进行数据处理，当达到时间或者数量的阈值后再批量提交到数据库。
- 写数据时使用批量插入的方式提高数据库写入速度


##### 4. 当前版本不足：
 - 1. 由于pg事件颗粒度是整行记录维度的通知，所以颗粒度太大，后续将改进支持字段颗粒度的事件捕捉机制
 - 2. 时间仓促，分包管理比较混乱，后续将会继续整理
 
 ##### 5. 压测性能
    大约1000行记录，在不考虑机器翻译的情况下，单机能够支持1000 record/秒 的性能